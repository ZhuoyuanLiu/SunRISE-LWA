import os
from astropy.io import fits
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import matplotlib.dates as mdates
import cv2
from scipy.ndimage import median_filter, gaussian_filter
import math
import pandas as pd
def standardize_rows(arr):
    '''Standardize each row (subtract mean and divide by stdevs).'''
    mean_per_row = np.mean(arr, axis=1, keepdims=True)
    std_per_row = np.std(arr, axis=1, keepdims=True)
    epsilon = 1e-10
    std_per_row = np.maximum(std_per_row, epsilon)
    standardized_data = (arr - mean_per_row) / std_per_row
    return standardized_data

def normalize(arr):
    '''Normalize array to have values in range [0,255] for creating image.'''
    y = (arr - np.min(arr)) / (np.max(arr) - np.min(arr)) * 255
    return y

def apply_clahe(arr):
    '''Apply CLAHE to enhance contrast.'''
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 250))
    arr_clahe = clahe.apply(arr)
    return arr_clahe

def remove_vertlines(data, threshold_low, threshold_high):
    """Remove spikes in the data by identifying and excluding time indices with spikes."""
    # denoised_data = []
    # median_values = np.median(data, axis=0)
    # spike_indices = np.where(median_values > threshold)[0]
    # for index in spike_indices:
    #     data[:, index] = np.median(data[:,0:10], axis=1)

    median_values = np.mean(data[:, :10], axis=1)     # Median value of the first 10 time columns, considered as background # USING MEAN NOW
    # Create a mask where data exceeds the upper threshold or is below the lower threshold. THIS IS GOOD AT REMOVING VERTICAL LINES, BUT IT ALSO ENLARGES OTHER NOISES
    mask = (data > threshold_high) | (data < threshold_low)
    # Replace values where the mask is True with the median values
    denoised_data = np.where(mask, median_values[:, np.newaxis], data)

    # Calculate the median value of the first column, considered as background
    # background_median = np.mean(data, axis=0)[0]
    # print("background_median:", background_median)
    # # Calculate the mean value of each column
    # column_means = np.mean(data, axis=0)
    # print("column_means:",column_means)
    # # Identify columns where the mean value minus background median exceeds the threshold
    # spike_indices = np.where(column_means - background_median[np.newaxis] > threshold_high)[0]
    # print("spike_indices:",spike_indices)
    # # Replace the identified columns with the background median value
    # denoised_data = data.copy()
    # denoised_data[:, spike_indices] =  np.full( (data.shape[0], len(spike_indices)), background_median)
    # # Locate time points on light curve and then remove 
    # print(denoised_data[:, spike_indices])

    return denoised_data

def filter_signals(data):
    # Apply median filtering
    # data_median = median_filter(data, size=(5, 5))
    # Apply wavelet denoising
    # data_wavelet = wavelet_denoise(data)
    data_median = median_filter(data, size=(5, 5))
    # Standardize and normalize the data
    standardized_data = standardize_rows(data_median)
    normalized_data = normalize(standardized_data).astype(np.uint8)
    data_gaussain = gaussian_filter(data,sigma=1)
    #data_median = median_filter(normalized_data, size=(5, 5))
    #data_wavelet = wavelet_denoise(normalized_data)
    return data_gaussain 

def crop_signal_area(data, timerange, freqrange):
    # data_cropped = data[:int(freqrange), :int(timerange)]
    data_cropped = data[int(freqrange), int(timerange)]
    return data_cropped
    
    

def create_imgs(fits_dir, save_imgs_folder):
    fits_files = os.listdir(fits_dir)
    mean_values_list = []
    for i, filename in enumerate(fits_files):
        image_save_path = os.path.join(save_imgs_folder, filename.split(".")[0] + '.png')
        lightcurve_save_path = os.path.join(save_imgs_folder, filename.split(".")[0] + 'lightcurve.png')
        fits_path = os.path.join(fits_dir, filename)
        fits_file = fits.open(fits_path)
        fits_data = fits_file[0].data[:-10, :]
        header = fits_file[0].header
        # Calculate the mean value of each column
        mean_values = np.mean(fits_data, axis=0)
        mean_values_list.append(mean_values)

        
        # Extract time and frequency information
        time_start_str = header['DATE-OBS'] + 'T' + header['TIME-OBS']
        time_start = datetime.strptime(time_start_str, '%Y/%m/%dT%H:%M:%S.%f')
        time_interval = header['CDELT1']
        num_time_points = fits_data.shape[1]
        file_time_data = [time_start + timedelta(seconds=i*time_interval) for i in range(num_time_points)]
      

        channel_num = header['CRVAL2']
        freq_interval = (90 - 45) / channel_num
        freq_start = 45 + freq_interval*10
        frequency_data = [freq_start + i * freq_interval for i in range(fits_data.shape[0])]



        # Process data
        dmean = np.mean(fits_data, axis=1,keepdims=True)
        dflat = fits_data - dmean # Try subtraction background first. - No much difference

        standardized = normalize(standardize_rows( dflat )).astype(np.uint8)
        #enhanced = apply_clahe(standardized)
        removed_vet = remove_vertlines(standardized,  threshold_low=50, threshold_high=100)
        
        filterd_data = filter_signals(removed_vet)      # Apply a filter to further denoise the image
        
        # Also crop the time range as needed.
        timerange = int(3600 / 8)
        # timerange = [1000:2000]
        # freqrange = [-40:-1]
        # cropped_data = crop_signal_area(removed_vet, timerange, freqrange)
        cropped_data =   removed_vet  [-130:-1, : ]
        frequency_data = frequency_data[1:130]
        # file_time_data = file_time_data[0: int(3600/8) ]
        # Plotting
        fig, ax = plt.subplots(figsize=(10, 5))
        im = ax.imshow(standardized, aspect='auto', origin='upper',
                       extent=[mdates.date2num(file_time_data[0]), mdates.date2num(file_time_data[-1]),
                               frequency_data[0], frequency_data[-1]], cmap='jet')
        ax.xaxis_date()
        date_format = mdates.DateFormatter('%H:%M:%S')
        ax.xaxis.set_major_formatter(date_format)

        # Customize the time tick intervals
        ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=5))
        ax.xaxis.set_minor_locator(mdates.SecondLocator(interval=30))

        #plt.colorbar(im, ax=ax, label='Intensity')
        # Add a colorbar
        cbar = fig.colorbar(im)
        # Set the colorbar label and adjust its font size
        cbar.set_label('Intensity [digit]', fontsize=14)  # Change the font size here
        # Adjust the fontsize of the colorbar tick labels
        #cbar.ax.tick_params(labelsize=15)  # Change the font size of tick labels here
        plt.xlabel('Observation Time [EST]', fontsize=14)
        plt.ylabel('Frequency [MHz]',fontsize=14)
        #plt.xticks(rotation=45)
        plt.tight_layout()
        #plt.title("2024/4/17 Peach Moutain Type V", fontsize=16)
        plt.savefig(image_save_path, dpi=300, bbox_inches='tight')
        plt.close()

        # Save mean values to a CSV file
        # mean_values_df = pd.DataFrame(mean_values_list)
        # mean_values_df.to_csv(os.path.join(save_imgs_folder, "mean_values.csv"), index=False)

        #Plotting the mean values along the time axis
        # plt.figure(figsize=(10, 5))
        # plt.plot(file_time_data, mean_values, label='Mean Value', color='blue')
        # plt.xlabel('Time [YY/MM/DD HH:MM:SS]')
        # plt.ylabel('Mean Intensity')
        # plt.title('Mean Intensity along Time Axis')
        # plt.xticks(rotation=45)
        # plt.grid(True)
        # plt.legend()
        # plt.tight_layout()
        # plt.savefig(lightcurve_save_path, dpi=300, bbox_inches='tight')
        # plt.close()

        # Plotting light curve for each frequency channel
        # freq_wanted = 67
        # freq_diff = (90-freq_wanted)
        # lightcurve_save_path = os.path.join(save_imgs_folder, f'{filename.split(".")[0]}_lightcurve_{freq_wanted:.1f}MHz.png')
        # channel_index = math.ceil( freq_diff/freq_interval )
        # print("channel_index:",channel_index)
        # lightcurve = df.iloc[:, channel_index]

        # fig, ax = plt.subplots(figsize=(10, 5))
        # try:
        #     ax.plot(file_time_data, lightcurve, label=f'Light Curve at {67:.1f} MHz')
        #     ax.xaxis_date()
        #     ax.xaxis.set_major_formatter(date_format)
        #     ax.set_xlabel('Time [YY/MM/DD HH:MM:SS]')
        #     ax.set_ylabel('Intensity')
        #     ax.legend()
        # except:
        #     pass
        # plt.xticks(rotation=45)
        # plt.tight_layout()
        # plt.savefig(lightcurve_save_path, dpi=300, bbox_inches='tight')
        # plt.close()


        # Print status updates
        if i % 50 == 0:
            print(f"{i}/{len(fits_files)}")
    print("done")

if __name__ == "__main__":
    fits_folder = "INDIANA"        # folder that contains FITS files
    save_imgs_folder = "colored images/colored_Indiana"  # folder to save created images
    os.makedirs(save_imgs_folder, exist_ok=True)
    create_imgs(fits_folder, save_imgs_folder)
